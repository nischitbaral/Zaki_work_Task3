{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c521d5e-2506-4ab0-83a9-3f2b8fe26ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85087141-8025-4252-9113-0889cafb2ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/30 10:36:25 WARN Utils: Your hostname, nischit-baral resolves to a loopback address: 127.0.1.1; using 10.10.42.113 instead (on interface enp2s0)\n",
      "25/04/30 10:36:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/30 10:36:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('provider_new').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b17181a-7759-49d3-b52c-4a54c28b8add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.10.42.113:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>provider_new</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c443842ec20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792f6b5a-aaa6-44bd-87e2-7c7b33eb08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- billing_code: string (nullable = true)\n",
      " |-- billing_code_type: string (nullable = true)\n",
      " |-- negotiation_arrangement: string (nullable = true)\n",
      " |-- billing_class: string (nullable = true)\n",
      " |-- negotiated_rate: double (nullable = true)\n",
      " |-- billing_code_modifier: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- negotiated_type: string (nullable = true)\n",
      " |-- service_code: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- provider_group_id: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_read = spark.read.parquet('in_prov.parquet')\n",
    "# df_read.printSchema()\n",
    "df_read = spark.read.parquet('in_net.parquet')\n",
    "df_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb692bff-b402-40d0-a060-fab2af4c5e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/30 10:36:39 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"my_pgdb\",\n",
    "    user=\"postgres\",\n",
    "    password=\"admin\",\n",
    "    host=\"localhost\",\n",
    "    port=5432\n",
    ")\n",
    "# conn.autocommit = True\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/my_pgdb\"\n",
    "connection_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"admin\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61b4448f-4f42-4f9e-bd3a-595f2a77def4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cur = conn.cursor()\n",
    "# create_table_query = \"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS provider1_data (\n",
    "#     provider_group_id BIGINT,\n",
    "#     npi BIGINT,\n",
    "#     tin_type SMALLINT,\n",
    "#     tin TEXT\n",
    "# );\n",
    "# \"\"\"\n",
    "# cur.execute(create_table_query)\n",
    "\n",
    "\n",
    "# df_read.write.jdbc(url=jdbc_url,table=\"provider1_data\",mode=\"append\", properties=connection_properties)\n",
    "\n",
    "\n",
    "\n",
    "# conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6236d0b5-45c3-40e1-89b3-8ee8dfe22e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS network1_data (\n",
    "    billing_code TEXT,\n",
    "    billing_code_type TEXT,\n",
    "    negotiation_arrangement TEXT,\n",
    "    provider_group_id BIGINT,\n",
    "    billing_class TEXT,\n",
    "    billing_code_modifier TEXT[],\n",
    "    negotiated_rate DOUBLE PRECISION,\n",
    "    negotiated_type TEXT,\n",
    "    service_code INTEGER[]\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "384eea42-5e7a-419c-9aa1-84a969b30e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_read.write.jdbc(url=jdbc_url,table=\"network1_data\",mode=\"append\", properties=connection_properties)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd6bb4-9dda-485f-9529-060419969872",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02d7d2-5d62-4b4b-9a4b-c2de08b9d912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9de66-de7b-4f10-b3e0-13d85b489bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
